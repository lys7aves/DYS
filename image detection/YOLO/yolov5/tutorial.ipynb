{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ultralytics/yolov5/blob/master/tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t6MPjfT5NrKQ"
   },
   "source": [
    "<a align=\"left\" href=\"https://ultralytics.com/yolov5\" target=\"_blank\">\n",
    "<img src=\"https://user-images.githubusercontent.com/26833433/125273437-35b3fc00-e30d-11eb-9079-46f313325424.png\"></a>\n",
    "\n",
    "This is the **official YOLOv5 🚀 notebook** by **Ultralytics**, and is freely available for redistribution under the [GPL-3.0 license](https://choosealicense.com/licenses/gpl-3.0/). \n",
    "For more information please visit https://github.com/ultralytics/yolov5 and https://ultralytics.com. Thank you!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7mGmQbAO5pQb"
   },
   "source": [
    "# Setup\n",
    "\n",
    "Clone repo, install dependencies and check PyTorch and GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wbvMlHd_QwMG",
    "outputId": "4d67116a-43e9-4d84-d19e-1edd83f23a04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete. Using torch 1.9.0+cpu (CPU)\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/ultralytics/yolov5  # clone repo\n",
    "%cd yolov5\n",
    "%pip install -qr requirements.txt  # install dependencies\n",
    "\n",
    "import torch\n",
    "from IPython.display import Image, clear_output  # to display images\n",
    "\n",
    "clear_output()\n",
    "print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4JnkELT0cIJg"
   },
   "source": [
    "# 1. Inference\n",
    "\n",
    "`detect.py` runs YOLOv5 inference on a variety of sources, downloading models automatically from the [latest YOLOv5 release](https://github.com/ultralytics/yolov5/releases), and saving results to `runs/detect`. Example inference sources are:\n",
    "\n",
    "```shell\n",
    "python detect.py --source 0  # webcam\n",
    "                          file.jpg  # image \n",
    "                          file.mp4  # video\n",
    "                          path/  # directory\n",
    "                          path/*.jpg  # glob\n",
    "                          'https://youtu.be/NUsoVlDFqZg'  # YouTube\n",
    "                          'rtsp://example.com/media.mp4'  # RTSP, RTMP, HTTP stream\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zR9ZbuQCH7FX",
    "outputId": "8b728908-81ab-4861-edb0-4d0c46c439fb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%rm` not found.\n"
     ]
    }
   ],
   "source": [
    "%rm -rf runs\n",
    "!python detect.py --weights yolov5s.pt --img 640 --conf 0.25 --source data/images/\n",
    "#Image(filename='runs/detect/exp/zidane.jpg', width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hkAzDWJ7cWTr"
   },
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<img align=\"left\" src=\"https://user-images.githubusercontent.com/26833433/127574988-6a558aa1-d268-44b9-bf6b-62d4c605cc72.jpg\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0eq1SMWl6Sfn"
   },
   "source": [
    "# 2. Validate\n",
    "Validate a model's accuracy on [COCO](https://cocodataset.org/#home) val or test-dev datasets. Models are downloaded automatically from the [latest YOLOv5 release](https://github.com/ultralytics/yolov5/releases). To show results by class use the `--verbose` flag. Note that `pycocotools` metrics may be ~1% better than the equivalent repo metrics, as is visible below, due to slight differences in mAP computation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eyTZYGgRjnMc"
   },
   "source": [
    "## COCO val2017\n",
    "Download [COCO val 2017](https://github.com/ultralytics/yolov5/blob/74b34872fdf41941cddcf243951cdb090fbac17b/data/coco.yaml#L14) dataset (1GB - 5000 images), and test model accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 48,
     "referenced_widgets": [
      "484511f272e64eab8b42e68dac5f7a66",
      "78cceec059784f2bb36988d3336e4d56",
      "ab93d8b65c134605934ff9ec5efb1bb6",
      "30df865ded4c434191bce772c9a82f3a",
      "20cdc61eb3404f42a12b37901b0d85fb",
      "2d7239993a9645b09b221405ac682743",
      "17b5a87f92104ec7ab96bf507637d0d2",
      "2358bfb2270247359e94b066b3cc3d1f",
      "3e984405db654b0b83b88b2db08baffd",
      "654d8a19b9f949c6bbdaf8b0875c931e",
      "896030c5d13b415aaa05032818d81a6e"
     ]
    },
    "id": "WQPtK1QYVaD_",
    "outputId": "7e6f5c96-c819-43e1-cd03-d3b9878cf8de"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "986d9b041af84080bcc9965e7f93b23b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/780M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Download COCO val2017\n",
    "torch.hub.download_url_to_file('https://github.com/ultralytics/yolov5/releases/download/v1.0/coco2017val.zip', 'tmp.zip')\n",
    "!unzip -q tmp.zip -d ../datasets && rm tmp.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X58w8JLpMnjH",
    "outputId": "3dd0e2fc-aecf-4108-91b1-6392da1863cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mdata=.\\data\\coco.yaml, weights=['yolov5x.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.65, task=val, device=, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=True, project=runs/val, name=exp, exist_ok=False, half=True\n",
      "Downloading https://github.com/ultralytics/yolov5/releases/download/v5.0/yolov5x.pt to yolov5x.pt...\n",
      "\n",
      "                 all       5000      36335      0.745      0.627       0.68       0.49\n",
      "Speed: 0.7ms pre-process, 860.1ms inference, 3.5ms NMS per image at shape (32, 3, 640, 640)\n",
      "\n",
      "Evaluating pycocotools mAP... saving runs\\val\\exp\\yolov5x_predictions.json...\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m pycocotools not found and is required by YOLOv5, attempting auto-update...\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Command 'pip install 'pycocotools'' returned non-zero exit status 1.\n",
      "pycocotools unable to run: No module named 'pycocotools'\n",
      "Results saved to \u001b[1mruns\\val\\exp\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  2021-8-25 torch 1.9.0+cpu CPU\n",
      "\n",
      "\n",
      "  0%|          | 0.00/168M [00:00<?, ?B/s]\n",
      "  0%|          | 144k/168M [00:00<02:03, 1.43MB/s]\n",
      "  0%|          | 408k/168M [00:00<01:25, 2.05MB/s]\n",
      "  1%|          | 1.05M/168M [00:00<00:41, 4.17MB/s]\n",
      "  2%|1         | 2.90M/168M [00:00<00:17, 9.99MB/s]\n",
      "  2%|2         | 3.87M/168M [00:00<00:17, 9.83MB/s]\n",
      "  3%|3         | 5.05M/168M [00:00<00:16, 10.6MB/s]\n",
      "  4%|3         | 6.13M/168M [00:00<00:15, 10.8MB/s]\n",
      "  5%|4         | 7.65M/168M [00:00<00:15, 10.7MB/s]\n",
      "  6%|5         | 9.85M/168M [00:00<00:11, 14.1MB/s]\n",
      "  7%|6         | 11.4M/168M [00:01<00:11, 14.7MB/s]\n",
      "  8%|8         | 13.5M/168M [00:01<00:09, 16.9MB/s]\n",
      " 10%|9         | 16.1M/168M [00:01<00:08, 19.2MB/s]\n",
      " 11%|#         | 18.3M/168M [00:01<00:07, 20.2MB/s]\n",
      " 12%|#2        | 20.2M/168M [00:01<00:08, 17.6MB/s]\n",
      " 13%|#3        | 22.0M/168M [00:01<00:08, 17.7MB/s]\n",
      " 15%|#4        | 24.6M/168M [00:01<00:07, 19.9MB/s]\n",
      " 16%|#5        | 26.6M/168M [00:01<00:08, 18.2MB/s]\n",
      " 17%|#7        | 29.1M/168M [00:02<00:07, 19.7MB/s]\n",
      " 18%|#8        | 31.0M/168M [00:02<00:07, 19.6MB/s]\n",
      " 20%|#9        | 33.3M/168M [00:02<00:06, 20.6MB/s]\n",
      " 21%|##1       | 36.0M/168M [00:02<00:06, 22.6MB/s]\n",
      " 23%|##3       | 38.7M/168M [00:02<00:05, 24.1MB/s]\n",
      " 25%|##4       | 41.4M/168M [00:02<00:05, 25.0MB/s]\n",
      " 26%|##6       | 44.1M/168M [00:02<00:05, 24.9MB/s]\n",
      " 28%|##8       | 47.1M/168M [00:02<00:04, 26.3MB/s]\n",
      " 30%|##9       | 49.6M/168M [00:02<00:04, 25.8MB/s]\n",
      " 32%|###1      | 53.1M/168M [00:02<00:04, 28.9MB/s]\n",
      " 34%|###3      | 56.4M/168M [00:03<00:03, 30.2MB/s]\n",
      " 35%|###5      | 59.3M/168M [00:03<00:04, 27.4MB/s]\n",
      " 37%|###7      | 62.5M/168M [00:03<00:04, 27.4MB/s]\n",
      " 39%|###9      | 65.8M/168M [00:03<00:03, 27.7MB/s]\n",
      " 41%|####      | 68.5M/168M [00:03<00:03, 27.6MB/s]\n",
      " 43%|####2     | 71.7M/168M [00:03<00:03, 29.2MB/s]\n",
      " 45%|####4     | 75.1M/168M [00:03<00:03, 30.9MB/s]\n",
      " 47%|####6     | 78.1M/168M [00:03<00:03, 30.6MB/s]\n",
      " 48%|####8     | 81.1M/168M [00:03<00:02, 30.8MB/s]\n",
      " 50%|#####     | 84.1M/168M [00:04<00:03, 26.7MB/s]\n",
      " 52%|#####1    | 86.7M/168M [00:04<00:03, 26.1MB/s]\n",
      " 53%|#####3    | 89.3M/168M [00:04<00:03, 26.2MB/s]\n",
      " 55%|#####4    | 91.8M/168M [00:04<00:03, 23.2MB/s]\n",
      " 57%|#####6    | 95.5M/168M [00:04<00:02, 26.6MB/s]\n",
      " 59%|#####8    | 98.3M/168M [00:04<00:02, 27.3MB/s]\n",
      " 60%|######    | 101M/168M [00:04<00:02, 24.8MB/s] \n",
      " 62%|######2   | 104M/168M [00:04<00:02, 26.7MB/s]\n",
      " 64%|######3   | 107M/168M [00:05<00:02, 25.6MB/s]\n",
      " 65%|######5   | 110M/168M [00:05<00:02, 27.5MB/s]\n",
      " 67%|######7   | 113M/168M [00:05<00:02, 24.3MB/s]\n",
      " 69%|######8   | 116M/168M [00:05<00:02, 24.6MB/s]\n",
      " 70%|#######   | 118M/168M [00:05<00:02, 24.1MB/s]\n",
      " 72%|#######1  | 120M/168M [00:05<00:02, 23.2MB/s]\n",
      " 73%|#######3  | 123M/168M [00:05<00:02, 23.0MB/s]\n",
      " 74%|#######4  | 125M/168M [00:05<00:01, 22.9MB/s]\n",
      " 76%|#######5  | 127M/168M [00:05<00:01, 22.9MB/s]\n",
      " 78%|#######7  | 131M/168M [00:06<00:01, 27.3MB/s]\n",
      " 79%|#######9  | 133M/168M [00:06<00:01, 27.0MB/s]\n",
      " 81%|########  | 136M/168M [00:06<00:01, 23.4MB/s]\n",
      " 82%|########2 | 138M/168M [00:06<00:01, 22.6MB/s]\n",
      " 84%|########3 | 140M/168M [00:06<00:01, 22.5MB/s]\n",
      " 85%|########5 | 143M/168M [00:06<00:01, 23.0MB/s]\n",
      " 86%|########6 | 145M/168M [00:06<00:01, 22.2MB/s]\n",
      " 88%|########7 | 147M/168M [00:06<00:00, 21.8MB/s]\n",
      " 89%|########8 | 149M/168M [00:07<00:01, 12.1MB/s]\n",
      " 93%|#########2| 156M/168M [00:07<00:00, 21.4MB/s]\n",
      " 94%|#########4| 158M/168M [00:07<00:00, 22.8MB/s]\n",
      " 96%|#########5| 161M/168M [00:07<00:00, 22.9MB/s]\n",
      " 98%|#########7| 164M/168M [00:07<00:00, 23.8MB/s]\n",
      " 99%|#########9| 166M/168M [00:07<00:00, 23.9MB/s]\n",
      "100%|##########| 168M/168M [00:07<00:00, 22.3MB/s]\n",
      "Fusing layers... \n",
      "Model Summary: 476 layers, 87730285 parameters, 0 gradients\n",
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '..\\datasets\\coco\\val2017' images and labels...:   0%|          | 0/5000 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '..\\datasets\\coco\\val2017' images and labels...1 found, 0 missing, 0 empty, 0 corrupted:   0%|          | 1/5000 [00:04<6:11:41,  4.46s/it]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '..\\datasets\\coco\\val2017' images and labels...16 found, 0 missing, 0 empty, 0 corrupted:   0%|          | 16/5000 [00:04<17:03,  4.87it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '..\\datasets\\coco\\val2017' images and labels...84 found, 0 missing, 0 empty, 0 corrupted:   2%|1         | 84/5000 [00:04<02:26, 33.51it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '..\\datasets\\coco\\val2017' images and labels...162 found, 0 missing, 0 empty, 0 corrupted:   3%|3         | 162/5000 [00:04<01:03, 76.10it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '..\\datasets\\coco\\val2017' images and labels...245 found, 1 missing, 0 empty, 0 corrupted:   5%|4         | 246/5000 [00:04<00:35, 133.69it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '..\\datasets\\coco\\val2017' images and labels...317 found, 1 missing, 0 empty, 0 corrupted:   6%|6         | 318/5000 [00:04<00:24, 190.62it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '..\\datasets\\coco\\val2017' images and labels...397 found, 3 missing, 0 empty, 0 corrupted:   8%|8         | 400/5000 [00:05<00:17, 265.86it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '..\\datasets\\coco\\val2017' images and labels...478 found, 4 missing, 0 empty, 0 corrupted:  10%|9         | 482/5000 [00:05<00:13, 346.63it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '..\\datasets\\coco\\val2017' images and labels...554 found, 6 missing, 0 empty, 0 corrupted:  11%|#1        | 560/5000 [00:05<00:10, 419.49it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '..\\datasets\\coco\\val2017' images and labels...629 found, 6 missing, 0 empty, 0 corrupted:  13%|#2        | 635/5000 [00:05<00:09, 482.42it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '..\\datasets\\coco\\val2017' images and labels...703 found, 6 missing, 0 empty, 0 corrupted:  14%|#4        | 709/5000 [00:05<00:07, 538.61it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '..\\datasets\\coco\\val2017' images and labels...777 found, 6 missing, 0 empty, 0 corrupted:  16%|#5        | 783/5000 [00:05<00:07, 583.76it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '..\\datasets\\coco\\val2017' images and labels...856 found, 8 missing, 0 empty, 0 corrupted:  17%|#7        | 864/5000 [00:05<00:06, 636.13it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '..\\datasets\\coco\\val2017' images and labels...931 found, 8 missing, 0 empty, 0 corrupted:  19%|#8        | 939/5000 [00:05<00:06, 658.66it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '..\\datasets\\coco\\val2017' images and labels...1005 found, 9 missing, 0 empty, 0 corrupted:  20%|##        | 1014/5000 [00:05<00:06, 650.94it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '..\\datasets\\coco\\val2017' images and labels...1075 found, 10 missing, 0 empty, 0 corrupted:  22%|##1       | 1085/5000 [00:06<00:06, 651.41it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '..\\datasets\\coco\\val2017' images and labels...1154 found, 10 missing, 0 empty, 0 corrupted:  23%|##3       | 1164/5000 [00:06<00:05, 683.77it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '..\\datasets\\coco\\val2017' images and labels...1227 found, 10 missing, 0 empty, 0 corrupted:  25%|##4       | 1237/5000 [00:06<00:05, 695.34it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '..\\datasets\\coco\\val2017' images and labels...1304 found, 10 missing, 0 empty, 0 corrupted:  26%|##6       | 1314/5000 [00:06<00:05, 709.71it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '..\\datasets\\coco\\val2017' images and labels...1382 found, 10 missing, 0 empty, 0 corrupted:  28%|##7       | 1392/5000 [00:06<00:04, 728.10it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '..\\datasets\\coco\\val2017' images and labels...1460 found, 10 missing, 0 empty, 0 corrupted:  29%|##9       | 1470/5000 [00:06<00:04, 737.70it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '..\\datasets\\coco\\val2017' images and labels...1533 found, 12 missing, 0 empty, 0 corrupted:  31%|###       | 1545/5000 [00:06<00:04, 732.52it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '..\\datasets\\coco\\val2017' images and labels...1610 found, 12 missing, 0 empty, 0 corrupted:  32%|###2      | 1622/5000 [00:06<00:04, 738.60it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '..\\datasets\\coco\\val2017' images and labels...1686 found, 12 missing, 0 empty, 0 corrupted:  34%|###3      | 1698/5000 [00:06<00:04, 743.89it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '..\\datasets\\coco\\val2017' images and labels...1759 found, 14 missing, 0 empty, 0 corrupted:  35%|###5      | 1773/5000 [00:06<00:04, 738.16it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '..\\datasets\\coco\\val2017' images and labels...1837 found, 14 missing, 0 empty, 0 corrupted:  37%|###7      | 1851/5000 [00:07<00:04, 746.10it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '..\\datasets\\coco\\val2017' images and labels...1917 found, 14 missing, 0 empty, 0 corrupted:  39%|###8      | 1931/5000 [00:07<00:04, 751.97it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '..\\datasets\\coco\\val2017' images and labels...1994 found, 16 missing, 0 empty, 0 corrupted:  40%|####      | 2010/5000 [00:07<00:03, 762.90it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '..\\datasets\\coco\\val2017' images and labels...2074 found, 16 missing, 0 empty, 0 corrupted:  42%|####1     | 2090/5000 [00:07<00:03, 768.18it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '..\\datasets\\coco\\val2017' images and labels...2158 found, 17 missing, 0 empty, 0 corrupted:  44%|####3     | 2175/5000 [00:07<00:03, 785.27it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '..\\datasets\\coco\\val2017' images and labels...2238 found, 18 missing, 0 empty, 0 corrupted:  45%|####5     | 2256/5000 [00:07<00:03, 790.36it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '..\\datasets\\coco\\val2017' images and labels...2315 found, 22 missing, 0 empty, 0 corrupted:  47%|####6     | 2337/5000 [00:07<00:03, 792.38it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '..\\datasets\\coco\\val2017' images and labels...2394 found, 23 missing, 0 empty, 0 corrupted:  48%|####8     | 2417/5000 [00:07<00:03, 793.29it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '..\\datasets\\coco\\val2017' images and labels...2474 found, 23 missing, 0 empty, 0 corrupted:  50%|####9     | 2497/5000 [00:07<00:03, 790.60it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '..\\datasets\\coco\\val2017' images and labels...2554 found, 23 missing, 0 empty, 0 corrupted:  52%|#####1    | 2577/5000 [00:07<00:03, 772.88it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '..\\datasets\\coco\\val2017' images and labels...2632 found, 23 missing, 0 empty, 0 corrupted:  53%|#####3    | 2655/5000 [00:08<00:03, 767.27it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '..\\datasets\\coco\\val2017' images and labels...2714 found, 26 missing, 0 empty, 0 corrupted:  55%|#####4    | 2740/5000 [00:08<00:02, 790.44it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '..\\datasets\\coco\\val2017' images and labels...2793 found, 27 missing, 0 empty, 0 corrupted:  56%|#####6    | 2820/5000 [00:08<00:02, 788.43it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '..\\datasets\\coco\\val2017' images and labels...2876 found, 28 missing, 0 empty, 0 corrupted:  58%|#####8    | 2904/5000 [00:08<00:02, 797.02it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '..\\datasets\\coco\\val2017' images and labels...2955 found, 29 missing, 0 empty, 0 corrupted:  60%|#####9    | 2984/5000 [00:08<00:02, 787.92it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '..\\datasets\\coco\\val2017' images and labels...3034 found, 29 missing, 0 empty, 0 corrupted:  61%|######1   | 3063/5000 [00:08<00:02, 775.64it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '..\\datasets\\coco\\val2017' images and labels...3112 found, 29 missing, 0 empty, 0 corrupted:  63%|######2   | 3141/5000 [00:08<00:02, 761.72it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '..\\datasets\\coco\\val2017' images and labels...3188 found, 30 missing, 0 empty, 0 corrupted:  64%|######4   | 3218/5000 [00:08<00:02, 761.58it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '..\\datasets\\coco\\val2017' images and labels...3272 found, 31 missing, 0 empty, 0 corrupted:  66%|######6   | 3303/5000 [00:08<00:02, 785.38it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '..\\datasets\\coco\\val2017' images and labels...3353 found, 32 missing, 0 empty, 0 corrupted:  68%|######7   | 3385/5000 [00:08<00:02, 787.32it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '..\\datasets\\coco\\val2017' images and labels...3432 found, 32 missing, 0 empty, 0 corrupted:  69%|######9   | 3464/5000 [00:09<00:02, 756.43it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '..\\datasets\\coco\\val2017' images and labels...3506 found, 34 missing, 0 empty, 0 corrupted:  71%|#######   | 3540/5000 [00:09<00:02, 712.44it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '..\\datasets\\coco\\val2017' images and labels...3584 found, 34 missing, 0 empty, 0 corrupted:  72%|#######2  | 3618/5000 [00:09<00:01, 729.15it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '..\\datasets\\coco\\val2017' images and labels...3658 found, 34 missing, 0 empty, 0 corrupted:  74%|#######3  | 3692/5000 [00:09<00:01, 717.36it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '..\\datasets\\coco\\val2017' images and labels...3731 found, 34 missing, 0 empty, 0 corrupted:  75%|#######5  | 3765/5000 [00:09<00:01, 699.06it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '..\\datasets\\coco\\val2017' images and labels...3807 found, 34 missing, 0 empty, 0 corrupted:  77%|#######6  | 3841/5000 [00:09<00:01, 710.87it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '..\\datasets\\coco\\val2017' images and labels...3878 found, 35 missing, 0 empty, 0 corrupted:  78%|#######8  | 3913/5000 [00:09<00:01, 700.04it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '..\\datasets\\coco\\val2017' images and labels...3948 found, 36 missing, 0 empty, 0 corrupted:  80%|#######9  | 3984/5000 [00:09<00:01, 697.45it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '..\\datasets\\coco\\val2017' images and labels...4023 found, 37 missing, 0 empty, 0 corrupted:  81%|########1 | 4060/5000 [00:09<00:01, 714.20it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '..\\datasets\\coco\\val2017' images and labels...4105 found, 39 missing, 0 empty, 0 corrupted:  83%|########2 | 4144/5000 [00:10<00:01, 744.62it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '..\\datasets\\coco\\val2017' images and labels...4184 found, 40 missing, 0 empty, 0 corrupted:  84%|########4 | 4224/5000 [00:10<00:01, 751.72it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '..\\datasets\\coco\\val2017' images and labels...4260 found, 40 missing, 0 empty, 0 corrupted:  86%|########6 | 4300/5000 [00:10<00:00, 711.18it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '..\\datasets\\coco\\val2017' images and labels...4331 found, 41 missing, 0 empty, 0 corrupted:  87%|########7 | 4372/5000 [00:10<00:00, 704.29it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '..\\datasets\\coco\\val2017' images and labels...4401 found, 42 missing, 0 empty, 0 corrupted:  89%|########8 | 4443/5000 [00:10<00:00, 686.93it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '..\\datasets\\coco\\val2017' images and labels...4471 found, 42 missing, 0 empty, 0 corrupted:  90%|######### | 4513/5000 [00:10<00:00, 689.21it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '..\\datasets\\coco\\val2017' images and labels...4545 found, 43 missing, 0 empty, 0 corrupted:  92%|#########1| 4588/5000 [00:10<00:00, 703.31it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '..\\datasets\\coco\\val2017' images and labels...4626 found, 45 missing, 0 empty, 0 corrupted:  93%|#########3| 4671/5000 [00:10<00:00, 735.43it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '..\\datasets\\coco\\val2017' images and labels...4707 found, 46 missing, 0 empty, 0 corrupted:  95%|#########5| 4753/5000 [00:10<00:00, 752.95it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '..\\datasets\\coco\\val2017' images and labels...4787 found, 48 missing, 0 empty, 0 corrupted:  97%|#########6| 4835/5000 [00:11<00:00, 763.95it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '..\\datasets\\coco\\val2017' images and labels...4864 found, 48 missing, 0 empty, 0 corrupted:  98%|#########8| 4912/5000 [00:11<00:00, 673.80it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '..\\datasets\\coco\\val2017' images and labels...4937 found, 48 missing, 0 empty, 0 corrupted: 100%|#########9| 4985/5000 [00:11<00:00, 683.02it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '..\\datasets\\coco\\val2017' images and labels...4952 found, 48 missing, 0 empty, 0 corrupted: 100%|##########| 5000/5000 [00:11<00:00, 443.21it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: ..\\datasets\\coco\\val2017.cache\n",
      "\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:   0%|          | 0/157 [00:00<?, ?it/s]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:   1%|          | 1/157 [00:17<46:01, 17.70s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:   1%|1         | 2/157 [00:38<50:59, 19.74s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:   2%|1         | 3/157 [01:00<52:46, 20.56s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:   3%|2         | 4/157 [01:21<53:12, 20.87s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:   3%|3         | 5/157 [01:43<53:18, 21.04s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:   4%|3         | 6/157 [02:04<53:34, 21.29s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:   4%|4         | 7/157 [02:27<54:41, 21.88s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:   5%|5         | 8/157 [02:50<54:49, 22.07s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:   6%|5         | 9/157 [03:13<55:08, 22.36s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:   6%|6         | 10/157 [03:36<55:38, 22.71s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:   7%|7         | 11/157 [03:59<55:18, 22.73s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:   8%|7         | 12/157 [04:23<55:22, 22.91s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:   8%|8         | 13/157 [04:45<54:56, 22.89s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:   9%|8         | 14/157 [05:09<54:46, 22.98s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  10%|9         | 15/157 [05:34<55:57, 23.65s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  10%|#         | 16/157 [05:58<56:05, 23.87s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  11%|#         | 17/157 [06:22<55:52, 23.95s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  11%|#1        | 18/157 [06:46<55:32, 23.97s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  12%|#2        | 19/157 [07:11<55:49, 24.27s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  13%|#2        | 20/157 [07:35<54:56, 24.06s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  13%|#3        | 21/157 [07:58<53:46, 23.73s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  14%|#4        | 22/157 [08:23<54:08, 24.06s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  15%|#4        | 23/157 [08:48<54:23, 24.35s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  15%|#5        | 24/157 [09:12<53:51, 24.29s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  16%|#5        | 25/157 [09:35<52:47, 24.00s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  17%|#6        | 26/157 [09:59<51:59, 23.81s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  17%|#7        | 27/157 [10:23<51:56, 23.97s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  18%|#7        | 28/157 [10:46<51:06, 23.77s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  18%|#8        | 29/157 [11:09<50:18, 23.58s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  19%|#9        | 30/157 [11:33<49:46, 23.51s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  20%|#9        | 31/157 [11:56<49:31, 23.58s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  20%|##        | 32/157 [12:20<49:01, 23.53s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  21%|##1       | 33/157 [12:44<48:50, 23.64s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  22%|##1       | 34/157 [13:08<48:58, 23.89s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  22%|##2       | 35/157 [13:33<49:23, 24.29s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  23%|##2       | 36/157 [13:57<48:34, 24.09s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  24%|##3       | 37/157 [14:20<47:39, 23.83s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  24%|##4       | 38/157 [14:44<47:11, 23.79s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  25%|##4       | 39/157 [15:07<46:34, 23.68s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  25%|##5       | 40/157 [15:31<45:57, 23.57s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  26%|##6       | 41/157 [15:54<45:37, 23.60s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  27%|##6       | 42/157 [16:17<44:46, 23.36s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  27%|##7       | 43/157 [16:42<45:02, 23.71s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  28%|##8       | 44/157 [17:05<44:22, 23.56s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  29%|##8       | 45/157 [17:28<43:29, 23.30s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  29%|##9       | 46/157 [17:50<42:44, 23.11s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  30%|##9       | 47/157 [18:13<41:56, 22.88s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  31%|###       | 48/157 [18:35<41:16, 22.72s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  31%|###1      | 49/157 [18:57<40:46, 22.66s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  32%|###1      | 50/157 [19:20<40:18, 22.61s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  32%|###2      | 51/157 [19:43<39:57, 22.62s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  33%|###3      | 52/157 [20:05<39:28, 22.56s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  34%|###3      | 53/157 [20:27<39:01, 22.52s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  34%|###4      | 54/157 [20:50<38:46, 22.59s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  35%|###5      | 55/157 [21:16<40:15, 23.68s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  36%|###5      | 56/157 [21:41<40:31, 24.07s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  36%|###6      | 57/157 [22:06<40:26, 24.26s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  37%|###6      | 58/157 [22:31<40:14, 24.39s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  38%|###7      | 59/157 [22:55<39:58, 24.47s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  38%|###8      | 60/157 [23:20<39:36, 24.50s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  39%|###8      | 61/157 [23:47<40:20, 25.21s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  39%|###9      | 62/157 [24:14<40:51, 25.80s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  40%|####      | 63/157 [24:41<41:09, 26.27s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  41%|####      | 64/157 [25:09<41:23, 26.70s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  41%|####1     | 65/157 [25:37<41:23, 26.99s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  42%|####2     | 66/157 [26:04<40:58, 27.02s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  43%|####2     | 67/157 [26:32<41:01, 27.35s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  43%|####3     | 68/157 [26:59<40:27, 27.28s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  44%|####3     | 69/157 [27:26<40:03, 27.31s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  45%|####4     | 70/157 [27:54<39:38, 27.33s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  45%|####5     | 71/157 [28:22<39:25, 27.51s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  46%|####5     | 72/157 [28:50<39:06, 27.61s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  46%|####6     | 73/157 [29:18<38:55, 27.80s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  47%|####7     | 74/157 [29:48<39:26, 28.51s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  48%|####7     | 75/157 [30:17<39:05, 28.61s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  48%|####8     | 76/157 [30:45<38:15, 28.34s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  49%|####9     | 77/157 [31:13<37:38, 28.23s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  50%|####9     | 78/157 [31:43<37:54, 28.79s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  50%|#####     | 79/157 [32:12<37:27, 28.82s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  51%|#####     | 80/157 [32:40<36:52, 28.73s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  52%|#####1    | 81/157 [33:08<36:15, 28.63s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  52%|#####2    | 82/157 [33:37<35:45, 28.60s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  53%|#####2    | 83/157 [34:05<35:11, 28.54s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  54%|#####3    | 84/157 [34:34<34:40, 28.50s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  54%|#####4    | 85/157 [35:05<35:06, 29.26s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  55%|#####4    | 86/157 [35:35<34:56, 29.53s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  55%|#####5    | 87/157 [36:04<34:11, 29.30s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  56%|#####6    | 88/157 [36:34<33:51, 29.45s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  57%|#####6    | 89/157 [37:03<33:30, 29.57s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  57%|#####7    | 90/157 [37:31<32:24, 29.03s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  58%|#####7    | 91/157 [38:00<31:46, 28.89s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  59%|#####8    | 92/157 [38:28<31:13, 28.82s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  59%|#####9    | 93/157 [38:57<30:35, 28.68s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  60%|#####9    | 94/157 [39:25<30:03, 28.63s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  61%|######    | 95/157 [39:54<29:31, 28.57s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  61%|######1   | 96/157 [40:22<28:55, 28.46s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  62%|######1   | 97/157 [40:53<29:08, 29.13s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  62%|######2   | 98/157 [41:24<29:22, 29.88s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  63%|######3   | 99/157 [41:55<29:14, 30.25s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  64%|######3   | 100/157 [42:27<29:05, 30.62s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  64%|######4   | 101/157 [42:56<28:15, 30.27s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  65%|######4   | 102/157 [43:28<28:12, 30.78s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  66%|######5   | 103/157 [43:58<27:19, 30.36s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  66%|######6   | 104/157 [44:26<26:19, 29.80s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  67%|######6   | 105/157 [44:54<25:26, 29.36s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  68%|######7   | 106/157 [45:23<24:41, 29.05s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  68%|######8   | 107/157 [45:51<23:58, 28.76s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  69%|######8   | 108/157 [46:21<23:47, 29.12s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  69%|######9   | 109/157 [46:50<23:25, 29.28s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  70%|#######   | 110/157 [47:20<22:59, 29.36s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  71%|#######   | 111/157 [47:51<22:59, 29.99s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  71%|#######1  | 112/157 [48:27<23:39, 31.54s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  72%|#######1  | 113/157 [49:03<24:12, 33.02s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  73%|#######2  | 114/157 [49:41<24:41, 34.46s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  73%|#######3  | 115/157 [50:21<25:15, 36.09s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  74%|#######3  | 116/157 [51:02<25:45, 37.69s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  75%|#######4  | 117/157 [51:40<25:07, 37.69s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  75%|#######5  | 118/157 [52:17<24:26, 37.59s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  76%|#######5  | 119/157 [52:55<23:45, 37.50s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  76%|#######6  | 120/157 [53:29<22:32, 36.56s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  77%|#######7  | 121/157 [54:01<21:11, 35.32s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  78%|#######7  | 122/157 [54:33<19:59, 34.27s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  78%|#######8  | 123/157 [55:02<18:29, 32.62s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  79%|#######8  | 124/157 [55:31<17:24, 31.65s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  80%|#######9  | 125/157 [56:00<16:28, 30.88s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  80%|########  | 126/157 [56:30<15:42, 30.40s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  81%|########  | 127/157 [56:59<15:02, 30.08s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  82%|########1 | 128/157 [57:28<14:21, 29.72s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  82%|########2 | 129/157 [57:57<13:48, 29.59s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  83%|########2 | 130/157 [58:33<14:07, 31.38s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  83%|########3 | 131/157 [59:09<14:10, 32.73s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  84%|########4 | 132/157 [59:45<14:08, 33.94s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  85%|########4 | 133/157 [1:00:22<13:52, 34.67s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  85%|########5 | 134/157 [1:00:58<13:26, 35.06s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  86%|########5 | 135/157 [1:01:34<12:57, 35.32s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  87%|########6 | 136/157 [1:02:10<12:26, 35.56s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  87%|########7 | 137/157 [1:02:46<11:54, 35.70s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  88%|########7 | 138/157 [1:03:23<11:25, 36.06s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  89%|########8 | 139/157 [1:03:53<10:18, 34.37s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  89%|########9 | 140/157 [1:04:20<09:07, 32.21s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  90%|########9 | 141/157 [1:04:46<08:05, 30.34s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  90%|######### | 142/157 [1:05:12<07:13, 28.91s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  91%|#########1| 143/157 [1:05:38<06:32, 28.06s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  92%|#########1| 144/157 [1:06:09<06:16, 28.95s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  92%|#########2| 145/157 [1:06:41<05:57, 29.82s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  93%|#########2| 146/157 [1:07:13<05:35, 30.46s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  94%|#########3| 147/157 [1:07:45<05:08, 30.90s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  94%|#########4| 148/157 [1:08:17<04:40, 31.19s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  95%|#########4| 149/157 [1:08:48<04:11, 31.38s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  96%|#########5| 150/157 [1:09:20<03:40, 31.49s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  96%|#########6| 151/157 [1:09:52<03:09, 31.54s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  97%|#########6| 152/157 [1:10:24<02:38, 31.61s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  97%|#########7| 153/157 [1:10:55<02:06, 31.55s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  98%|#########8| 154/157 [1:11:23<01:31, 30.40s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  99%|#########8| 155/157 [1:11:47<00:57, 28.62s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95:  99%|#########9| 156/157 [1:12:10<00:26, 26.98s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|##########| 157/157 [1:12:16<00:00, 20.47s/it]\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100%|##########| 157/157 [1:12:16<00:00, 27.62s/it]WARNING: Ignoring invalid distribution -ip (d:\\users\\anaconda3\\lib\\site-packages)\n",
      "ERROR: Invalid requirement: \"'pycocotools'\"\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\users\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\users\\anaconda3\\lib\\site-packages)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run YOLOv5x on COCO val2017\n",
    "!python val.py --weights yolov5x.pt --data coco.yaml --img 640 --iou 0.65 --half"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rc_KbFk0juX2"
   },
   "source": [
    "## COCO test-dev2017\n",
    "Download [COCO test2017](https://github.com/ultralytics/yolov5/blob/74b34872fdf41941cddcf243951cdb090fbac17b/data/coco.yaml#L15) dataset (7GB - 40,000 images), to test model accuracy on test-dev set (**20,000 images, no labels**). Results are saved to a `*.json` file which should be **zipped** and submitted to the evaluation server at https://competitions.codalab.org/competitions/20794."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "V0AJnSeCIHyJ"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d0e76fc19dc4015a2a0e8898cd10cb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/67.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rm: cannot remove '#': No such file or directory\n",
      "rm: cannot remove 'unzip': No such file or directory\n",
      "rm: cannot remove 'labels': No such file or directory\n",
      "'f'은(는) 내부 또는 외부 명령, 실행할 수 있는 프로그램, 또는\n",
      "배치 파일이 아닙니다.\n",
      "UsageError: Line magic function `%mv` not found.\n"
     ]
    }
   ],
   "source": [
    "# Download COCO test-dev2017\n",
    "torch.hub.download_url_to_file('https://github.com/ultralytics/yolov5/releases/download/v1.0/coco2017labels.zip', 'tmp.zip')\n",
    "!unzip -q tmp.zip -d ../ && rm tmp.zip # unzip labels\n",
    "!f=\"test2017.zip\" && curl http://images.cocodataset.org/zips/$f -o $f && unzip -q $f && rm $f  # 7GB,  41k images\n",
    "%mv ./test2017 ../coco/images  # move to /coco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "29GJXAP_lPrt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mdata=.\\data\\coco.yaml, weights=['yolov5s.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.6, task=test, device=, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=True, project=runs/val, name=exp, exist_ok=False, half=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  2021-8-25 torch 1.9.0+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 224 layers, 7266973 parameters, 0 gradients\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\LeeYuseop\\Jupyter Notebook\\DYS\\YOLO\\yolov5\\utils\\datasets.py\", line 395, in __init__\n",
      "    raise Exception(f'{prefix}{p} does not exist')\n",
      "Exception: \u001b[34m\u001b[1mtest: \u001b[0m..\\datasets\\coco\\test-dev2017.txt does not exist\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"val.py\", line 354, in <module>\n",
      "    main(opt)\n",
      "  File \"val.py\", line 329, in main\n",
      "    run(**vars(opt))\n",
      "  File \"d:\\Users\\anaconda3\\lib\\site-packages\\torch\\autograd\\grad_mode.py\", line 28, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"val.py\", line 147, in run\n",
      "    dataloader = create_dataloader(data[task], imgsz, batch_size, gs, single_cls, pad=0.5, rect=True,\n",
      "  File \"E:\\LeeYuseop\\Jupyter Notebook\\DYS\\YOLO\\yolov5\\utils\\datasets.py\", line 98, in create_dataloader\n",
      "    dataset = LoadImagesAndLabels(path, imgsz, batch_size,\n",
      "  File \"E:\\LeeYuseop\\Jupyter Notebook\\DYS\\YOLO\\yolov5\\utils\\datasets.py\", line 400, in __init__\n",
      "    raise Exception(f'{prefix}Error loading data from {path}: {e}\\nSee {HELP_URL}')\n",
      "Exception: \u001b[34m\u001b[1mtest: \u001b[0mError loading data from ..\\datasets\\coco\\test-dev2017.txt: \u001b[34m\u001b[1mtest: \u001b[0m..\\datasets\\coco\\test-dev2017.txt does not exist\n",
      "See https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data\n"
     ]
    }
   ],
   "source": [
    "# Run YOLOv5s on COCO test-dev2017 using --task test\n",
    "!python val.py --weights yolov5s.pt --data coco.yaml --task test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VUOiNLtMP5aG"
   },
   "source": [
    "# 3. Train\n",
    "\n",
    "Download [COCO128](https://www.kaggle.com/ultralytics/coco128), a small 128-image tutorial dataset, start tensorboard and train YOLOv5s from a pretrained checkpoint for 3 epochs (note actual training is typically much longer, around **300-1000 epochs**, depending on your dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Knxi2ncxWffW"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46dafe3c6c094e17bd47d1e6478dba33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/6.66M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Download COCO128\n",
    "torch.hub.download_url_to_file('https://github.com/ultralytics/yolov5/releases/download/v1.0/coco128.zip', 'tmp.zip')\n",
    "!unzip -q tmp.zip -d ../datasets && rm tmp.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_pOkGLv1dMqh"
   },
   "source": [
    "Train a YOLOv5s model on [COCO128](https://www.kaggle.com/ultralytics/coco128) with `--data coco128.yaml`, starting from pretrained `--weights yolov5s.pt`, or from randomly initialized `--weights '' --cfg yolov5s.yaml`. Models are downloaded automatically from the [latest YOLOv5 release](https://github.com/ultralytics/yolov5/releases), and **COCO, COCO128, and VOC datasets are downloaded automatically** on first use.\n",
    "\n",
    "All training results are saved to `runs/train/` with incrementing run directories, i.e. `runs/train/exp2`, `runs/train/exp3` etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "bOy5KI2ncnWd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-d8322305782dc5ce\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-d8322305782dc5ce\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tensorboard  (optional)\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "2fLAV42oNb7M"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ip (d:\\users\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\users\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\users\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\users\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\users\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\users\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\users\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\users\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\users\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\users\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\users\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\users\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\users\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\users\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\users\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\users\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: You can find your API key in your browser here: https://wandb.ai/authorize\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wandb: Paste an API key from your profile and hit enter: ········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Appending key for api.wandb.ai to your netrc file: C:\\Users\\SAMSUNG/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Weights & Biases  (optional)\n",
    "%pip install -q wandb\n",
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1NcFxRcFdJ_O",
    "outputId": "00ea4b14-a75c-44a2-a913-03b431b69de5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=coco128.yaml, hyp=data/hyps/hyp.scratch.yaml, epochs=3, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, adam=False, sync_bn=False, workers=8, project=runs/train, entity=None, name=exp, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=-1, artifact_alias=latest, local_rank=-1, freeze=0\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  2021-8-25 torch 1.9.0+cpu CPU\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 602, in <module>\n",
      "    main(opt)\n",
      "  File \"train.py\", line 500, in main\n",
      "    train(opt.hyp, opt, device)\n",
      "  File \"train.py\", line 72, in train\n",
      "    hyp = yaml.safe_load(f)  # load hyps dict\n",
      "  File \"d:\\Users\\anaconda3\\lib\\site-packages\\yaml\\__init__.py\", line 162, in safe_load\n",
      "    return load(stream, SafeLoader)\n",
      "  File \"d:\\Users\\anaconda3\\lib\\site-packages\\yaml\\__init__.py\", line 112, in load\n",
      "    loader = Loader(stream)\n",
      "  File \"d:\\Users\\anaconda3\\lib\\site-packages\\yaml\\loader.py\", line 34, in __init__\n",
      "    Reader.__init__(self, stream)\n",
      "  File \"d:\\Users\\anaconda3\\lib\\site-packages\\yaml\\reader.py\", line 85, in __init__\n",
      "    self.determine_encoding()\n",
      "  File \"d:\\Users\\anaconda3\\lib\\site-packages\\yaml\\reader.py\", line 124, in determine_encoding\n",
      "    self.update_raw()\n",
      "  File \"d:\\Users\\anaconda3\\lib\\site-packages\\yaml\\reader.py\", line 178, in update_raw\n",
      "    data = self.stream.read(size)\n",
      "UnicodeDecodeError: 'cp949' codec can't decode byte 0xf0 in position 9: illegal multibyte sequence\n"
     ]
    }
   ],
   "source": [
    "# Train YOLOv5s on COCO128 for 3 epochs\n",
    "!python train.py --img 640 --batch 16 --epochs 3 --data coco128.yaml --weights yolov5s.pt --cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "15glLzbQx5u0"
   },
   "source": [
    "# 4. Visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DLI1JmHU7B0l"
   },
   "source": [
    "## Weights & Biases Logging 🌟 NEW\n",
    "\n",
    "[Weights & Biases](https://wandb.ai/site?utm_campaign=repo_yolo_notebook) (W&B) is now integrated with YOLOv5 for real-time visualization and cloud logging of training runs. This allows for better run comparison and introspection, as well improved visibility and collaboration for teams. To enable W&B `pip install wandb`, and then train normally (you will be guided through setup on first use). \n",
    "\n",
    "During training you will see live updates at [https://wandb.ai/home](https://wandb.ai/home?utm_campaign=repo_yolo_notebook), and you can create and share detailed [Reports](https://wandb.ai/glenn-jocher/yolov5_tutorial/reports/YOLOv5-COCO128-Tutorial-Results--VmlldzozMDI5OTY) of your results. For more information see the [YOLOv5 Weights & Biases Tutorial](https://github.com/ultralytics/yolov5/issues/1289). \n",
    "\n",
    "<img align=\"left\" src=\"https://user-images.githubusercontent.com/26833433/125274843-a27bc600-e30e-11eb-9a44-62af0b7a50a2.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-WPvRbS5Swl6"
   },
   "source": [
    "## Local Logging\n",
    "\n",
    "All results are logged by default to `runs/train`, with a new experiment directory created for each new training as `runs/train/exp2`, `runs/train/exp3`, etc. View train and val jpgs to see mosaics, labels, predictions and augmentation effects. Note an Ultralytics **Mosaic Dataloader** is used for training (shown below), which combines 4 images into 1 mosaic during training.\n",
    "\n",
    "> <img src=\"https://user-images.githubusercontent.com/26833433/124931219-48bf8700-e002-11eb-84f0-e05d95b118dd.jpg\" width=\"700\">  \n",
    "`train_batch0.jpg` shows train batch 0 mosaics and labels\n",
    "\n",
    "> <img src=\"https://user-images.githubusercontent.com/26833433/124931217-4826f080-e002-11eb-87b9-ae0925a8c94b.jpg\" width=\"700\">  \n",
    "`test_batch0_labels.jpg` shows val batch 0 labels\n",
    "\n",
    "> <img src=\"https://user-images.githubusercontent.com/26833433/124931209-46f5c380-e002-11eb-9bd5-7a3de2be9851.jpg\" width=\"700\">  \n",
    "`test_batch0_pred.jpg` shows val batch 0 _predictions_\n",
    "\n",
    "Training results are automatically logged to [Tensorboard](https://www.tensorflow.org/tensorboard) and [CSV](https://github.com/ultralytics/yolov5/pull/4148) as `results.csv`, which is plotted as `results.png` (below) after training completes. You can also plot any `results.csv` file manually:\n",
    "\n",
    "```python\n",
    "from utils.plots import plot_results \n",
    "plot_results('path/to/results.csv')  # plot 'results.csv' as 'results.png'\n",
    "```\n",
    "\n",
    "<img align=\"left\" width=\"800\" alt=\"COCO128 Training Results\" src=\"https://user-images.githubusercontent.com/26833433/126906780-8c5e2990-6116-4de6-b78a-367244a33ccf.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zelyeqbyt3GD"
   },
   "source": [
    "# Environments\n",
    "\n",
    "YOLOv5 may be run in any of the following up-to-date verified environments (with all dependencies including [CUDA](https://developer.nvidia.com/cuda)/[CUDNN](https://developer.nvidia.com/cudnn), [Python](https://www.python.org/) and [PyTorch](https://pytorch.org/) preinstalled):\n",
    "\n",
    "- **Google Colab and Kaggle** notebooks with free GPU: <a href=\"https://colab.research.google.com/github/ultralytics/yolov5/blob/master/tutorial.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a> <a href=\"https://www.kaggle.com/ultralytics/yolov5\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" alt=\"Open In Kaggle\"></a>\n",
    "- **Google Cloud** Deep Learning VM. See [GCP Quickstart Guide](https://github.com/ultralytics/yolov5/wiki/GCP-Quickstart)\n",
    "- **Amazon** Deep Learning AMI. See [AWS Quickstart Guide](https://github.com/ultralytics/yolov5/wiki/AWS-Quickstart)\n",
    "- **Docker Image**. See [Docker Quickstart Guide](https://github.com/ultralytics/yolov5/wiki/Docker-Quickstart) <a href=\"https://hub.docker.com/r/ultralytics/yolov5\"><img src=\"https://img.shields.io/docker/pulls/ultralytics/yolov5?logo=docker\" alt=\"Docker Pulls\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Qu7Iesl0p54"
   },
   "source": [
    "# Status\n",
    "\n",
    "![CI CPU testing](https://github.com/ultralytics/yolov5/workflows/CI%20CPU%20testing/badge.svg)\n",
    "\n",
    "If this badge is green, all [YOLOv5 GitHub Actions](https://github.com/ultralytics/yolov5/actions) Continuous Integration (CI) tests are currently passing. CI tests verify correct operation of YOLOv5 training ([train.py](https://github.com/ultralytics/yolov5/blob/master/train.py)), testing ([val.py](https://github.com/ultralytics/yolov5/blob/master/val.py)), inference ([detect.py](https://github.com/ultralytics/yolov5/blob/master/detect.py)) and export ([export.py](https://github.com/ultralytics/yolov5/blob/master/export.py)) on MacOS, Windows, and Ubuntu every 24 hours and on every commit.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IEijrePND_2I"
   },
   "source": [
    "# Appendix\n",
    "\n",
    "Optional extras below. Unit tests validate repo functionality and should be run on any PRs submitted.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "mcKoSIK2WSzj"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: val.py [-h] [--data DATA] [--weights WEIGHTS [WEIGHTS ...]]\n",
      "              [--batch-size BATCH_SIZE] [--imgsz IMGSZ]\n",
      "              [--conf-thres CONF_THRES] [--iou-thres IOU_THRES] [--task TASK]\n",
      "              [--device DEVICE] [--single-cls] [--augment] [--verbose]\n",
      "              [--save-txt] [--save-hybrid] [--save-conf] [--save-json]\n",
      "              [--project PROJECT] [--name NAME] [--exist-ok] [--half]\n",
      "val.py: error: unrecognized arguments: # speed\n",
      "usage: val.py [-h] [--data DATA] [--weights WEIGHTS [WEIGHTS ...]]\n",
      "              [--batch-size BATCH_SIZE] [--imgsz IMGSZ]\n",
      "              [--conf-thres CONF_THRES] [--iou-thres IOU_THRES] [--task TASK]\n",
      "              [--device DEVICE] [--single-cls] [--augment] [--verbose]\n",
      "              [--save-txt] [--save-hybrid] [--save-conf] [--save-json]\n",
      "              [--project PROJECT] [--name NAME] [--exist-ok] [--half]\n",
      "val.py: error: unrecognized arguments: # mAP\n",
      "usage: val.py [-h] [--data DATA] [--weights WEIGHTS [WEIGHTS ...]]\n",
      "              [--batch-size BATCH_SIZE] [--imgsz IMGSZ]\n",
      "              [--conf-thres CONF_THRES] [--iou-thres IOU_THRES] [--task TASK]\n",
      "              [--device DEVICE] [--single-cls] [--augment] [--verbose]\n",
      "              [--save-txt] [--save-hybrid] [--save-conf] [--save-json]\n",
      "              [--project PROJECT] [--name NAME] [--exist-ok] [--half]\n",
      "val.py: error: unrecognized arguments: # speed\n",
      "usage: val.py [-h] [--data DATA] [--weights WEIGHTS [WEIGHTS ...]]\n",
      "              [--batch-size BATCH_SIZE] [--imgsz IMGSZ]\n",
      "              [--conf-thres CONF_THRES] [--iou-thres IOU_THRES] [--task TASK]\n",
      "              [--device DEVICE] [--single-cls] [--augment] [--verbose]\n",
      "              [--save-txt] [--save-hybrid] [--save-conf] [--save-json]\n",
      "              [--project PROJECT] [--name NAME] [--exist-ok] [--half]\n",
      "val.py: error: unrecognized arguments: # mAP\n",
      "usage: val.py [-h] [--data DATA] [--weights WEIGHTS [WEIGHTS ...]]\n",
      "              [--batch-size BATCH_SIZE] [--imgsz IMGSZ]\n",
      "              [--conf-thres CONF_THRES] [--iou-thres IOU_THRES] [--task TASK]\n",
      "              [--device DEVICE] [--single-cls] [--augment] [--verbose]\n",
      "              [--save-txt] [--save-hybrid] [--save-conf] [--save-json]\n",
      "              [--project PROJECT] [--name NAME] [--exist-ok] [--half]\n",
      "val.py: error: unrecognized arguments: # speed\n",
      "usage: val.py [-h] [--data DATA] [--weights WEIGHTS [WEIGHTS ...]]\n",
      "              [--batch-size BATCH_SIZE] [--imgsz IMGSZ]\n",
      "              [--conf-thres CONF_THRES] [--iou-thres IOU_THRES] [--task TASK]\n",
      "              [--device DEVICE] [--single-cls] [--augment] [--verbose]\n",
      "              [--save-txt] [--save-hybrid] [--save-conf] [--save-json]\n",
      "              [--project PROJECT] [--name NAME] [--exist-ok] [--half]\n",
      "val.py: error: unrecognized arguments: # mAP\n",
      "usage: val.py [-h] [--data DATA] [--weights WEIGHTS [WEIGHTS ...]]\n",
      "              [--batch-size BATCH_SIZE] [--imgsz IMGSZ]\n",
      "              [--conf-thres CONF_THRES] [--iou-thres IOU_THRES] [--task TASK]\n",
      "              [--device DEVICE] [--single-cls] [--augment] [--verbose]\n",
      "              [--save-txt] [--save-hybrid] [--save-conf] [--save-json]\n",
      "              [--project PROJECT] [--name NAME] [--exist-ok] [--half]\n",
      "val.py: error: unrecognized arguments: # speed\n",
      "usage: val.py [-h] [--data DATA] [--weights WEIGHTS [WEIGHTS ...]]\n",
      "              [--batch-size BATCH_SIZE] [--imgsz IMGSZ]\n",
      "              [--conf-thres CONF_THRES] [--iou-thres IOU_THRES] [--task TASK]\n",
      "              [--device DEVICE] [--single-cls] [--augment] [--verbose]\n",
      "              [--save-txt] [--save-hybrid] [--save-conf] [--save-json]\n",
      "              [--project PROJECT] [--name NAME] [--exist-ok] [--half]\n",
      "val.py: error: unrecognized arguments: # mAP\n"
     ]
    }
   ],
   "source": [
    "# Reproduce\n",
    "for x in 'yolov5s', 'yolov5m', 'yolov5l', 'yolov5x':\n",
    "  !python val.py --weights {x}.pt --data coco.yaml --img 640 --conf 0.25 --iou 0.45  # speed\n",
    "  !python val.py --weights {x}.pt --data coco.yaml --img 640 --conf 0.001 --iou 0.65  # mAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "GMusP4OAxFu6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\SAMSUNG/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2021-8-25 torch 1.9.0+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 224 layers, 7266973 parameters, 0 gradients\n",
      "Adding AutoShape... \n",
      "image 1/2: 720x1280 2 persons, 2 ties\n",
      "image 2/2: 1080x810 4 persons, 1 bus\n",
      "Speed: 1006.5ms pre-process, 187.0ms inference, 1.5ms NMS per image at shape (2, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "# PyTorch Hub\n",
    "import torch\n",
    "\n",
    "# Model\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s')\n",
    "\n",
    "# Images\n",
    "dir = 'https://ultralytics.com/images/'\n",
    "imgs = [dir + f for f in ('zidane.jpg', 'bus.jpg')]  # batch of images\n",
    "\n",
    "# Inference\n",
    "results = model(imgs)\n",
    "results.print()  # or .show(), .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "FGH0ZjkGjejy"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-15-a32a66fb61f6>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-15-a32a66fb61f6>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    export PYTHONPATH=\"$PWD\"  # to run *.py. files in subdirectories\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Unit tests\n",
    "%%shell\n",
    "export PYTHONPATH=\"$PWD\"  # to run *.py. files in subdirectories\n",
    "\n",
    "rm -rf runs  # remove runs/\n",
    "for m in yolov5s; do  # models\n",
    "  python train.py --weights $m.pt --epochs 3 --img 320 --device 0  # train pretrained\n",
    "  python train.py --weights '' --cfg $m.yaml --epochs 3 --img 320 --device 0  # train scratch\n",
    "  for d in 0 cpu; do  # devices\n",
    "    python detect.py --weights $m.pt --device $d  # detect official\n",
    "    python detect.py --weights runs/train/exp/weights/best.pt --device $d  # detect custom\n",
    "    python val.py --weights $m.pt --device $d # val official\n",
    "    python val.py --weights runs/train/exp/weights/best.pt --device $d # val custom\n",
    "  done\n",
    "  python hubconf.py  # hub\n",
    "  python models/yolo.py --cfg $m.yaml  # inspect\n",
    "  python export.py --weights $m.pt --img 640 --batch 1  # export\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gogI-kwi3Tye"
   },
   "outputs": [],
   "source": [
    "# Profile\n",
    "from utils.torch_utils import profile\n",
    "\n",
    "m1 = lambda x: x * torch.sigmoid(x)\n",
    "m2 = torch.nn.SiLU()\n",
    "results = profile(input=torch.randn(16, 3, 640, 640), ops=[m1, m2], n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RVRSOhEvUdb5"
   },
   "outputs": [],
   "source": [
    "# Evolve\n",
    "!python train.py --img 640 --batch 64 --epochs 100 --data coco128.yaml --weights yolov5s.pt --cache --noautoanchor --evolve\n",
    "!d=runs/train/evolve && cp evolve.* $d && zip -r evolve.zip $d && gsutil mv evolve.zip gs://bucket  # upload results (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BSgFCAcMbk1R"
   },
   "outputs": [],
   "source": [
    "# VOC\n",
    "for b, m in zip([64, 48, 32, 16], ['yolov5s', 'yolov5m', 'yolov5l', 'yolov5x']):  # zip(batch_size, model)\n",
    "  !python train.py --batch {b} --weights {m}.pt --data VOC.yaml --epochs 50 --cache --img 512 --nosave --hyp hyp.finetune.yaml --project VOC --name {m}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "YOLOv5 Tutorial",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "17b5a87f92104ec7ab96bf507637d0d2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "20cdc61eb3404f42a12b37901b0d85fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_896030c5d13b415aaa05032818d81a6e",
      "placeholder": "​",
      "style": "IPY_MODEL_654d8a19b9f949c6bbdaf8b0875c931e",
      "value": " 780M/780M [00:33&lt;00:00, 24.4MB/s]"
     }
    },
    "2358bfb2270247359e94b066b3cc3d1f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2d7239993a9645b09b221405ac682743": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "30df865ded4c434191bce772c9a82f3a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3e984405db654b0b83b88b2db08baffd",
      "max": 818322941,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2358bfb2270247359e94b066b3cc3d1f",
      "value": 818322941
     }
    },
    "3e984405db654b0b83b88b2db08baffd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "484511f272e64eab8b42e68dac5f7a66": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ab93d8b65c134605934ff9ec5efb1bb6",
       "IPY_MODEL_30df865ded4c434191bce772c9a82f3a",
       "IPY_MODEL_20cdc61eb3404f42a12b37901b0d85fb"
      ],
      "layout": "IPY_MODEL_78cceec059784f2bb36988d3336e4d56"
     }
    },
    "654d8a19b9f949c6bbdaf8b0875c931e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "78cceec059784f2bb36988d3336e4d56": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "896030c5d13b415aaa05032818d81a6e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ab93d8b65c134605934ff9ec5efb1bb6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_17b5a87f92104ec7ab96bf507637d0d2",
      "placeholder": "​",
      "style": "IPY_MODEL_2d7239993a9645b09b221405ac682743",
      "value": "100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
